/*
 * Library based upon my api for scraping the internet. | v1.0.0
 * Created by Syed Daanish.
 * this library works in coordination with my site.
 * please visit https://localhost/ for more information.
 */
"use strict";var requestDataByClassname,requestDataById,getPage,scrapejs={HTML:"<mode=Html[object ScrapeJS]/>",TEXT:"<mode=Text[object ScrapeJS]/>"};navigator.onLine?(requestDataByClassname=function(e,t,r=!1){return new Promise((s,n)=>{"string"!=typeof e.address&&n("address is not provided or is not a string type."),"string"!=typeof e.class&&n("class is not provided or is not a string type.");let a=e.address.replace("&","[amp$").replace("=","[equ$");fetch("http://localhost/api.php?addr="+a+"&by=true").then(e=>e.text()).then(a=>{let o=a,i=" />\n<br />\n<b>Warning</b>:";if(o.includes(" />\n<br />\n<b>Warning</b>:"))throw"invalid request";try{if(null!=typeof window.DOMParser){var l=new DOMParser;if(null!=(d=l.parseFromString(o,"text/html")))var c=d;else{o=o.replace(/&/gi,"and");c=d=l.parseFromString(o,"text/xml")}}else{var d;(d=document.implementation.createHTMLDocument("")).write(o),d.close;c=d}}catch(i){throw"Error parsing html:\n"+i.message}let p=c.getElementsByClassName(e.class);null!=p||r?null==p&&r&&s(void 0):n("No elements found by the class "+e.class);let u=[];if(t==scrapejs.HTML);else if(t==scrapejs.TEXT){for(let e=0;e<p.length;e++)u.push(p[e].innerText);s(u)}else n("mode is not one of scrapejs.TEXT or scrapejs.HTML");s(p)})})},requestDataById=function(e,t){return new Promise((r,s)=>{"string"!=typeof e.address&&s("address is not provided or is not a string type."),"string"!=typeof e.id&&s("id is not provided or is not a string type."),"boolean"!=typeof e.loadScripts&&null!=e.loadScripts&&s("loadScripts should be boolean."),"boolean"!=typeof e.loadStylesheets&&null!=e.loadStylesheets&&s("loadStylesheets should be boolean.");let n=e.address.replace("&","[amp$").replace("=","[equ$");fetch("http://localhost/api.php?addr="+n+"&by=true").then(e=>e.text()).then(n=>{let a=n;if(a.includes(" />\n<br />\n<b>Warning</b>:"))throw"invalid request";let o=function(e){try{if(null!=typeof window.DOMParser){var t=new DOMParser;return null!=(r=t.parseFromString(e,"text/html"))?r:(e=e.replace(/&/gi,"and"),r=t.parseFromString(e,"text/xml"))}var r;return(r=document.implementation.createHTMLDocument("")).write(e),r.close,r}catch(e){throw"Error parsing html:\n"+e.message}},i=o(a),l=i.getElementById(e.id),c="";if(e.loadStylesheets)for(var d=i.getElementsByTagName("style"),p=0;p<d.length;p++)c+=d[p].outerHTML;if(e.loadScripts){var u=i.getElementsByTagName("script");for(p=0;p<u.length;p++)u[p].src&&("/"!=u[p].src.charAt(0)&&"."!=u[p].src.charAt(0)||u[p].setAttribute("src",e.address+"/"+u[p].src)),c+=u[p].outerHTML}"string"==typeof e.src&&l.hasAttribute(e.src)&&("/"!=l.getAttribute(e.src).charAt(0)&&"."!=l.getAttribute(e.src).charAt(0)||l.setAttribute(e.src,e.address+"/"+l.getAttribute(e.src))),t==scrapejs.HTML?((e.loadScripts||e.loadStylesheets)&&r(o('<div id="scrapedContent">'+c+l.outerHTML+"</div>").getElementById("scrapedContent")),r(l)):t==scrapejs.TEXT?r(l.innerHTML.replace(/\<(\/?)(.*?)\>/g,"")):s("mode is not one of scrapejs.TEXT or scrapejs.HTML")})})},getPage=function(e){return new Promise((t,r)=>{e=e.replace("&","[amp$").replace("=","[equ$"),fetch("http://localhost/api.php?addr="+e+"&by=true").then(e=>e.text()).then(e=>{let r=e,s=" />\n<br />\n<b>Warning</b>:";if(r.includes(" />\n<br />\n<b>Warning</b>:"))throw"invalid request";try{if(null!=typeof window.DOMParser){var n=new DOMParser;if(null!=(o=n.parseFromString(r,"text/html")))var a=o;else{r=r.replace(/&/gi,"and");a=o=n.parseFromString(r,"text/xml")}}else{var o;(o=document.implementation.createHTMLDocument("")).write(r),o.close;a=o}}catch(s){throw"Error parsing html:\n"+s.message}t(a)})})}):(requestDataByClassname=function(){return new Promise((e,t)=>{t("No internet")})},requestDataById=function(){return new Promise((e,t)=>{t("No internet")})},getPage=function(){return new Promise((e,t)=>{t("No internet")})});
